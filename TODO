Redis TODO and Roadmap

VERSION 1.2 TODO (Zsets, Integer encoding, Append only journal)
===============================================================

Most of the features already implemented for this release. The following is a list of the missing things in order to release the first beta tar.gz:

* Man pages for SRANDMEMBER, missing Z-commands, ...
* Write docs for the "STORE" operaiton of SORT. Link to the article about SORT by written by defunkt.
* ZRANGEBYSCORE LIMIT option and test.

VERSION 1.4 TODO (Hash type)
============================

* Hashes (HSET, HGET, HEXISTS, HLEN, ...).
* An utility able to export an .rdb file into a text-only JSON dump, we can't live anymore without such a tool. Probably an extension to redis-cli.

VERSION 1.6 TODO (Virtual memory)
=================================

* Redis Virtual Memory for datasets bigger than RAM (http://groups.google.com/group/redis-db/msg/752997c7b38553cd)

VERSION 1.8 TODO (Fault tollerant sharding)
===========================================

* Redis-cluster, a fast intermediate layer (proxy) that implements consistent hashing and fault tollerant nodes handling.

Interesting readings about this:

    - http://ayende.com/Blog/archive/2009/04/06/designing-rhino-dht-a-fault-tolerant-dynamically-distributed-hash.aspx

VERSION 2.0 TODO (Optimizations and latency)
============================================

* Lower the CPU usage.
* Lower the RAM usage everywhere possible.
* Use epool and alike to rewrite ae.c for Linux and other platforms suppporting fater-than-select() mutiplexing APIs.
* Implement an UDP interface for low-latency GET/SET operations.

VERSION 2.2 TODO (Optimizations and latency)
============================================

* JSON command able to access data serialized in JSON format. For instance if I've a key foobar with a json object I can alter the "name" file using somthing like: "JSON SET foobar name Kevin". We should have GET and INCRBY as well.

SHORT/LONG TERM RANDOM TODO ITEMS
=================================

 * FORK command (fork()s executing the commands received by the current
   client in the new process). Hint: large SORTs can use more cores,
   copy-on-write will avoid memory problems.
 * SORT: Don't copy the list into a vector when BY argument is constant.
 * Write the hash table size of every db in the dump, so that Redis can resize the hash table just one time when loading a big DB.
 * LOCK / TRYLOCK / UNLOCK as described many times in the google group
 * Replication automated tests
 * BYTEDARRAY type
 * zmalloc() should avoid to add a private header for archs where there is some other kind of libc-specific way to get the size of a malloced block.
 * Read-only mode.
